                      ----------------------------
                           Curl Cache Notes
                      ----------------------------
Curl request
   put in ram disk
   multi-threading
      queue multiple for same file
   allow file://protocol
   callbacks during download
      check cache size at:
         start of download
         after header if size known
         on completion
         when writing file
      test for out-of-memory condition
   download first to RAM?
      out of memory checking
   cleanup after aborts (including 404 with content)
   cancel curl request (implies identifying the request)
   signature to validate
   time server to set clock?
      otherwise, each reboot starts anew and newest can 
      become oldest.
      Not such a problem if cache is cleared (RAM disk)



Calls into the 'cache'

The curl cache can be thought of as a mutex-protected 
shared memory blackboard, through which the application makes
mostly asynchronous calls (with call-backs for completion
status), and from which a set of curl worker threads
pulls requests and posts status values.

   Main application entry points
   -----------------------------
   get/post
         details of request
            url
            post parameters
         onprogress callback  - indicates forward movement
         onfilesize callback  - indicates file size is known
         oncomplete callback  - ref counted file ptr handed off here
         oncancel callback
         onfailure callback

   cancelLoad  - cancel a pending transfer
      cancel operates on the entire URL, not just one request.
      This simplifies bookkeeping of the request.

   deleteFile
      details of request
         url
         post params

   openFile
      add a reference to a file (retrieving ptr/length)

   worker thread entry points
   --------------------------
   getRequest                 - called from reader thread
   completedRequest           - called from reader thread
   failedRequest              - called from reader thread
   cancelledRequest           - called from reader thread

Overview

                         requests                   requests
      application          ---->      Curl Cache      ---->     curl worker
      thread(s)                                                  thread(s)
                          <----                      <----
                        completion                   status
                       and progress                  values
                         callbacks

                                           ^
                                           |
                                           V
                                           
                                       disk cache


Data structure notes
   Cache consists of a handful of fairly separable things:

      1. Disk cache. This is entirely passive, synchronous, and
         controlled by the global curl cache lock.

         Called by application threads to
            clear some space for a pending transfer
            open a handle and mmap a cached item (when get is cached)
            close a handle and munmap a cached item
            delete an item from the persistent store
               (either synchronously in deleteFile call, or during
                handle close for deferred delete)

         Called by worker threads to
            delete some space to make room for incoming data
            store content of file

      2. Curl Active URL cache
         Consists of an array of 'active' cache entries. These
         entries may not yet have a disk/ram cache entry (not until
         a successful retrieval), but have at least one of the following:

            - an active worker request 
            - one or more active application requests.
            - one or more open file descriptors

         Active cache entries are removed when the last reference to
         them is invalidated from the list above. Their disk/ram entry 
         may remain (until a 'delete' call is made)

         The corresponding object (ccActiveURL.h/.cpp:curlCache_t) contains 
         the primary mutex used to coordinate accesses from the application 
         and worker threads.

      3. Worker request queue

         Simply a queue of file transfer requests to be performed. Each
         worker queue request is pointed to from its 'active' cache 
         entry. Active cache entries with an active worker request never
         have a corresponding disk cache entry.

      4. Application request list

         A set of application entries for each pending request. Pending
         here means the time between an initiating application call to
         the curl cache (get,post) and the corresponding final completion 
         callback (oncomplete,onfailure,oncancel). Note that 
         cancel is not an initiating call, since it requires an active
         entry, and does not generate an extra completion callback. Instead,
         it alters (if not too late) the completion callback to 'oncancel' 
         instead of 'oncomplete' or 'onfailure'.

      5. Application file handles

         These objects don't really live in the cache domain, but they are
         used to control reference counting to open file handles (and mmaps).
         Each of them has a pointer back to the Active URL Cache

Use/case analysis

   app thread issues get request.
   if in cache and 'no cache' flag
      if file in use, wait for unused (asynchronous)
      when unused, delete and callback if needed
   if not in cache
      clear some space based upon file type
      add entry to curl cache
         entry in scoreboard, status pending get/post
      chain client request to cache entry (doubly-linked list)
      insert new worker request
      return client request identifier
   else (in cache)
      call any progress functions
         file size
         bytes read      
      call oncomplete

Data structure linkages:


                              0/N:1      Active 
   app request             <---------> URL cache   <---->   worker request
         ^                         /        |          1:0/1
         |                       /          |
         V                   ----           |
   next app req for file   /                |
                          /                 |
                         /                  |
   file handle   -------- 0/N:1             |
                                            | 1:0/1
                                            |
                                            V
                                        Disk Cache


I'm tempted to have file handles talk directly to the disk cache, but deferred
delete makes this more appropriate for the Active URL cache. Deferred delete
requires an application request entry, and if the file handle points to the 
disk cache, either the disk cache needs to point back to the active URL cache
or to a list of app requests, making life messy(er).

The reason I'm tempted to have the file handle point to the disk cache is because
the disk cache needs to know the reference count status (0/1-N) of each file when
determining what it can throw out. I can accomplish the same thing by just keeping 
the reference count in the disk cache data structure.

But wait, I also need a reference count in the active URL cache for use by 
objects with protocol file://.

So, I'll just place a flag (inUse/not) in the disk cache and keep the reference
count in the active URL cache.

Actually, I'll also put the file open/mmap calls into the disk cache to mask the
fact that there's header information in the cache'd files.


                        Detailed data structure descriptions:
                        -------------------------------------

Disk Cache
----------

The disk cache is a process-global object whose primary purpose is to keep track of
how much disk space is in use, and manage a set of objects occupying that space.
In normal operation, it is expected that the cache is always 'full', and that each
failed request for an item in the cache will be followed by a set of requests for 
space.

The disk cache is passed a directory to be used for storage, which is normally /tmp/curl,
but can be overridden by the environment variable 'CURLTMPDIR'. If the directory does
not exist, it will be created.

The disk cache has a fixed maximum size over its' lifetime. If the CURLTMPSIZE 
environment variable is defined at startup, it will be used to define the size. 
Otherwise, a default amount of space is used (see ccDiskCache.cpp for current default).

In order to allow mmap'd access to non-cached files (e.g. posts and CGI requests), they
are stored in the disk cache along with persistent files, but are flagged for deletion
when their reference count goes to zero. This requires that an application use and consume
the content immediately during the 'oncomplete' handler.

Worker Threads
--------------

On startup, some number of curl worker threads will be started and handed a queue of
curl requests. Each of them will repeatedly pull requests from the queue until the queue
says 'abort'.

At startup, a number of callbacks are installed for use by all worker threads. 

No references are made in the ccWorker module to the active URL or disk caches.
This should happen inside the callbacks passed to the curl worker thread initialization
routine.

All of this allows the module to be developed and tested outside of the greater curl cache 
structure.


Active URL Cache
-------------------
In general, active URL cache entries serve as glue between the curl worker
threads, the disk cache, and the application request list. 

Each object in the active URL cache corresponds to a single URL.

More specifically, each entry in the active URL cache connects one or more
application requests or file handles to either the curl worker module or the 
disk cache. 

The data structure consists of 
   
   1. a doubly-linked list of application requests, and 
   
   2. information for either 
   
   a.)   a worker request URL, [post params], cancel flag
   b.)   the disk cache
            pointer and length of data
            non-zero reference count

Location of an URL from a URL is performed by a hash table lookup and
linear search. Note that a couple of things (file handles, get/post identifiers)
use pointers to active URL cache entries, so we need to firmly plant 
these in memory (no STL here!).

Application Request List
------------------------
The application request list is a set of unfulfilled requests from the application. 

The data is kept as a doubly-linked list of objects, pointed to from the application
URL cache (URL).

Each request contains a type (get,post) and a set of zero or more callbacks:
   onprogress callback
   onfilesize callback
   oncomplete callback
   oncancel callback
   onfailure callback

Application File Handles
------------------------
File handles are returned to an application as pointers into the active URL cache.
The active URL cache contains a reference count so that it knows the total number
outstanding, and can tell when it's okay to invalidate the entry (and possibly delete)
the file.


                        State and Transition logic
                        --------------------------

Because of the large number of combinations and events involved in the lifetime of an
active curl URL, I'm going to try and describe the behavior as a state machine.

States:
   Initial        - invalid object, no request URL
   Retrieving     - while URL in worker queue or worker is transferring
   Pending Cancel - same as Retrieving, but trying to cancel all requests
                    on this URL
   Open           - while one or more application fragments have the 
                    URL content open (and mmapped)
   Pending Delete - same as Open, but with command to delete from cache
                    when last handle is closed


Events: 
   Events marked with 'a' are app-generated, 'w' are worker generated
   Initiating events are marked with 'I'.
   
I  a - Get request
I  a - Post request
   a - Open request
   a - Cancel all request
   a - Delete request
   a - Close file handle
   w - Transfer progress
   w = Have file size
   w - Transfer completed
   w - Transfer failed
   w - Transfer cancelled

Actions: Rather than exhaustively list the 55 event/state combinations, I'll describe 
the actions by event since that's the primary thing we have coming in, and some
events do the same thing for URLs in multiple states.

   Get/Post requests
      Get requests in the initial state first check the cache (depending on app flag)
         and jump right to the 'open' state if the URL is found.
      Post requests always act like 'no cache' gets

      If the URL state is 'initial', the request is queued to a worker thread
      and a transition is made to the 'retrieving' state.

      If the URL is in the 'pending cancel' state, the request is fulfilled 
      immediately as 'cancelled'.

      If the URL state is 'Open' or 'pending delete', it remains in the same state and
      the request is fulfilled as 'Completed'.

   Open requests
      This should only occur when the file is in the 'open' state, generally during an
      'onComplete' callback.
      
      If so, this routine adds a reference and returns a pointer, length, and URL reference
      (for later use during a 'close file handle' event).

      If called at other times, this event generates an error return value

   Cancel all requests
      Same as 'Cancel' request, except that all matching, unfulfilled requests for the URL
      are processed.

   Delete request
      If the state is:              The code:
      ----------------              ---------
      Initial                       removes the requested file from cache and fulfills the request
      Retrieving/pending cancel     acts like 'cancel all'
      Open                          sets the state to 'pending delete' 
      Pending delete                no-op (already pending delete)

   Close file handle request
      This event should only occur in the open or pending delete states.
      It is not an initiating event, so it completes immediately.

      It decrements the use count and removes the reference to the disk cache.

      If the reference count is now zero. If the state is 'pending delete', 
      it tells the disk cache to delete the file

   Transfer completed event
      This event should only occur during the 'pending cancel' or 'retrieving'
      states.

      If 'pending cancel', this event is treated as a 'transfer cancelled event'
      as described below.
      
      If 'retrieving', this routine saves the file to the disk cache and fulfills
      any pending (get/post) requests. Fulfilling each request increments the use
      count (and causes an mmap in the disk cache). If this URL was 'posted', the 
      state is changed to 'pending delete', otherwise the state is changed to 'Open'.

   Transfer progress event
   Have file size event
      
      These two events should only occur in the retrieving state, and simply pass
      the callback to the application.
      
   Transfer cancelled event
      (Should only occur in state 'Pending Cancel')
      This routine fulfills all get or post requests with status 'cancelled'. 

      The state of the URL returns to 'Initial'.

   Transfer failed event

      If the state is 'pending cancel', this is treated exactly as a 'transfer cancelled'
      event.

      Otherwise (state=Retrieving), all pending get or post requests are fulfilled with
      status 'failed'.
      
      The state returns to 'Initial'.


                        File Layout
                        -----------

ccDiskCache.h/.cpp         declare and define the disk cache
ccWorker.h/.cpp            declare and define the curl worker thread interfaces

ccActiveURL.h/.cpp         declare and define the active url cache (curlCache_t)
                           and associated classes



                        Support for file:// protocol
                        ----------------------------

Okay, okay. Now that all of the above is complete, a few notes about support for the
file://protocol.

   1. We want the same use count tracking as in http:// entities
      so that we don't waste file handles.
   2. It makes absolutely no sense to cache file:// entities
      to disk, because they're already there.
   3. We don't want the application to care about the protocol.

Since the use count tracking is in the active URL cache, that's where we'll put 
file:// handling. What we need are a file handle and flag indicating that the 
disk info isn't in the cache, but directly opened/mmap'd.


                        Notes on threading and locks
                        ----------------------------

The general flow of control for objects which use the curl cache is:

      Javascript constructor or method call needs data from 
      curl cache. (i.e. image())

      The initializer for the object or method contains information
      about what is to be obtained (i.e. the URL), and what to do
      when it is loaded or cancelled:

         image({url:"http://my.machine/test.png", onLoad:"this.draw(0,0);"} );

      If the object is initialized using the 'new' keyword, the call is
      asynchronous, and the onLoad, onCancel, or onLoadError handlers are
      deferred until the main-line script is complete.
      
      If the object is 'new' keyword is not used, execution of the Javascript
      file containing the call stalls until the object is loaded. In other
      words, it is a synchronous call.

      Each of the function-specific methods calls the queueCurlRequest() routine
      to transfer the data, passing a callback routine to parse the data upon
      retrieval.
      
      queueCurlRequest() in turn constructs a request for the ccActiveURL module,
      and hands off callbacks in the form required by ccActiveURL.

      Here's where things get a little messy.
      
      From the caller's perspective, there is a single decision which affects the
      flow of control: whether the call is synchronous or asynchronous.
      
      From ccActiveURL's standpoint, though, there is another decision point:
      Is the data immediately available? If it is, ccActiveURL calls the supplied
      callbacks directly and never queues the request. This means that the callbacks
      can occur in the context of either the thread which calls get() or post()
      (for immediate results), or in the context of a worker thread.

      There are a couple of ramifications of these two variables. In the asynchronous 
      case, we want the completion handler to be executed in the C++ scope of the
      main Javascript thread at the end of script execution (i.e. through pollCodeQueue()).

      In the synchronous case, we want to stall execution of the Javascript thread
      until the finalizing callback from ccActiveURL, so that the results of the
      callbacks and handlers is available to the next line of Javascript.

      The result needs to be a lot like the modal message handlers in a Windows 
      application, in that some messages need to be trapped, and others queued
      to the main message pump.

                                             callbacks
      sync/async     immediate/deferred      trapped?
      ----------     ------------------      ----------
      sync           immediate                  yes
      sync           deferred                   yes
      async          immediate                  no
      async          deferred                   no

      A couple of thoughts on implementation of this:

         1. We could install a filter on the 'inbound' end of the code queue
            which diverts certain messages to a second queue.

            If we just implement this trap for callbacks, we can limit the 
            amount of code and data needed for the filter to either a pointer
            match on the callback data, or a combination of pointer match on
            the data with pointer match(es) on the callback function.

            In the case of the jsCurl callbacks, there are at least three 
            function pointers of interest: onComplete, onFailure, onCancel,
            but we'll also want to trap onProgress and onSize (and any others
            which get added later).

            We should probably re-implement the original code queue (scope,script,
            source) to use the callback method to get rid of the union and 
            if/else logic in the filter.

         2. We could add a routine to the 'outbound' end of the code queue which
            allows us to pull certain messages. The code queue is already set
            up as an std::list, so pulling messages from the middle is no
            big deal.


      Either way (g'zin or g'zout), we need a filter, and implementing a filter will
      be easier without the callback vs. code fragment duality in the code queue.
      
      Okay, the original code queue now generates a callback.

      Now on to the filter.
      
      Rather than implementing a generic "works for everyone" kind of filter framework
      for the one piece of code that needs it, it makes more sense to just have yet 
      another callback that can trap events.

      Install a callback and have it trap messages.

      Just for grins, I'm going to implement this as a C++ base class that can be
      overridden to provide specifics. The base class will provide insertion of
      itself into a chain of filters, and a wait() function to wait for events to
      come in.

      Derived class(es) will override the isHandled() and isDone() methods.

